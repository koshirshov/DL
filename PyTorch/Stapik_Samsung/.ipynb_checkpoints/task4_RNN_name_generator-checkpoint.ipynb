{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация текста с помощью RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(по мотивам [семинара](https://github.com/neychev/harbour_dlia2019/blob/master/day02_Simple_RNN/Day_2_Simple_RNN_pytorch.ipynb)\n",
    " [курса \"Deep Learning in Applications\"](https://in.harbour.space/data-science/deep-learning-in-applications-radoslav-neychev-anastasia-ianina/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:20:34.854793Z",
     "start_time": "2019-11-05T18:20:34.372865Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные\n",
    "Датасет содержит ~9k имен, все написаны латиницей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:03.509714Z",
     "start_time": "2019-11-05T18:21:03.491489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "with open('datasets/russian_names.txt') as input_file:\n",
    "    names = input_file.read()[:-1].split('\\n')\n",
    "    names = [' ' + line for line in names] #пробел добавили, чтобы при генерации не задавать букву а использовать пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:03.946758Z",
     "start_time": "2019-11-05T18:21:03.938432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Ababko', ' Abaev', ' Abagyan', ' Abaidulin', ' Abaidullin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение длин имен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:05.420060Z",
     "start_time": "2019-11-05T18:21:05.179513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Name length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.335188Z",
     "start_time": "2019-11-05T18:21:07.320148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  53\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = list(set(''.join(names)))\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Символы -> id\n",
    "\n",
    "Создадим словарь < символ > -> < id >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.674548Z",
     "start_time": "2019-11-05T18:21:07.671129Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.838814Z",
     "start_time": "2019-11-05T18:21:07.833611Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:07.988093Z",
     "start_time": "2019-11-05T18:21:07.977722Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_ix = [token_to_id[c] for c in data[i]]\n",
    "        data_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:08.136936Z",
     "start_time": "2019-11-05T18:21:08.131609Z"
    }
   },
   "outputs": [],
   "source": [
    "#Example: cast 4 names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000], token_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные нейронные сети\n",
    "\n",
    "<img src=\"img/rnn.png\" width=480>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:10.739438Z",
     "start_time": "2019-11-05T18:21:09.661222Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:10.751862Z",
     "start_time": "2019-11-05T18:21:10.741772Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, variable containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, variable containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1) #YOUR CODE HERE\n",
    "        h_next = self.rnn_update(x_and_h) #YOUR CODE HERE\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return Variable(torch.zeros(batch_size, self.num_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:11.071002Z",
     "start_time": "2019-11-05T18:21:11.052377Z"
    }
   },
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка сети, RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:11.521078Z",
     "start_time": "2019-11-05T18:21:11.510175Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_loop(rnn, batch_index):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_index.size()\n",
    "    hid_state = rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_index.transpose(0,1):\n",
    "        hid_state, logp_next = rnn(x_t, hid_state)  \n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренировка сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:12.120106Z",
     "start_time": "2019-11-05T18:21:12.109585Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.521061Z",
     "start_time": "2019-11-05T18:21:12.302892Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))###YOUR CODE\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # visualizing training process\n",
    "    history.append(loss.data.numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: генерация имен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.540765Z",
     "start_time": "2019-11-05T18:21:23.524503Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.625562Z",
     "start_time": "2019-11-05T18:21:23.544968Z"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.702249Z",
     "start_time": "2019-11-05T18:21:23.629226Z"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn, seed_phrase=' Ar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Более простое решение\n",
    "\n",
    "* `nn.RNNCell(emb_size, rnn_num_units)` - шаг RNN. Алгоритм: concat-linear-tanh\n",
    "* `nn.RNN(emb_size, rnn_num_units` - весь rnn_loop.\n",
    "\n",
    "Кроме того, в PyTorch есть `nn.LSTMCell`, `nn.LSTM`, `nn.GRUCell`, `nn.GRU`, etc. etc.\n",
    "\n",
    "Перепишем наш пример с генерацией имен с помощью средств PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.713285Z",
     "start_time": "2019-11-05T18:21:23.704755Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNNLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, Variable) and isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp\n",
    "    \n",
    "model = CharRNNLoop()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:23.790047Z",
     "start_time": "2019-11-05T18:21:23.715167Z"
    }
   },
   "outputs": [],
   "source": [
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "batch_ix = Variable(torch.LongTensor(batch_ix))\n",
    "\n",
    "logp_seq = model(batch_ix)\n",
    "\n",
    "# compute loss\n",
    "loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n",
    "                  batch_ix[:, :-1].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:31.468107Z",
     "start_time": "2019-11-05T18:21:23.792092Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(names, 32), token_to_id, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:25]) > np.mean(history[-25:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:31.526436Z",
     "start_time": "2019-11-05T18:21:31.469965Z"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: мотивационные лозунги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:31.570320Z",
     "start_time": "2019-11-05T18:21:31.528673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "with open('datasets/author_quotes.txt') as input_file:\n",
    "    quotes = input_file.read()[:-1].split('\\n')\n",
    "    quotes = [' ' + line for line in quotes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:31.575286Z",
     "start_time": "2019-11-05T18:21:31.571798Z"
    }
   },
   "outputs": [],
   "source": [
    "quotes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:21:31.653673Z",
     "start_time": "2019-11-05T18:21:31.578424Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = list(set(''.join(quotes)))\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "num_tokens = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что еще можно генерировать?\n",
    "С помощью кода из этого семинара можно генерировать не только имена, но и:\n",
    "\n",
    "* Повести/романы/поэзию/песни любимого автора\n",
    "* Новостные заголовки\n",
    "* Программный код\n",
    "* Молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system)\n",
    "* Музыку\n",
    "* Названия мебели из ИКЕА\n",
    "* Мотивационные лозунги\n",
    "* etc.\n",
    "\n",
    "__Удачи!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
